{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Section 2 Team 3\n",
    "\n",
    "The primary goal of this project is to evaluate and compare the effectiveness of traditional machine learning models with that of large language models (LLMs) for providing movie recommendations. Traditional ML models have been successfully used in various recommendation systems due to their ability to handle structured data efficiently. However, with advancements in LLMs that can understand and process natural language intricately, there is an opportunity to leverage these models for recommendations. \n",
    "\n",
    "We are performing this experiment using the Netflix Movie Dataset. \n",
    "\n",
    "Link to Github:\n",
    "> https://github.com/PhilipFelizarta/LLM-ML-Recommender-Study\n",
    "\n",
    "Link to Dataset:\n",
    "> https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Loading the data and performing necessary data cleaning and preprocessing steps.\n",
    "\n",
    "In this case, I am loading the data from two files, `combined_data_1.txt` and `movie_titles.csv`. The `combined_data_1.txt` file contains the movie ratings data, while the `movie_titles.csv` file contains the movie titles and release years.\n",
    "\n",
    "After cleaning and joining the data, I'm also enriching the data by adding the following features:\n",
    "- average rating per movie\n",
    "- number of ratings per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file_1 = \"combined_data_1.txt\"\n",
    "\n",
    "# Not loading all the data at once to reduce iteration time\n",
    "ratings = [ratings_file_1]\n",
    "movie_titles = \"movie_titles.csv\"\n",
    "dataset_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ratings_data(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        current_movie_id = None\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.endswith(':'):\n",
    "                current_movie_id = int(line.replace(':', ''))\n",
    "            else:\n",
    "                customer_id, rating, date = line.split(',')\n",
    "                data.append([current_movie_id, int(customer_id), float(rating), date])\n",
    "    return pd.DataFrame(data, columns=['Movie_Id', 'Cust_Id', 'Rating', 'Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.concat([load_ratings_data(f\"{dataset_path}/{rating}\") for rating in ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_count = df_ratings['Cust_Id'].nunique()\n",
    "movie_count = df_ratings['Movie_Id'].nunique()\n",
    "rating_count = df_ratings['Cust_Id'].count()\n",
    "\n",
    "\n",
    "print(f\"Total number of unique customers: {cust_count}\")\n",
    "\n",
    "p = df_ratings.groupby('Rating')['Rating'].agg(['count'])\n",
    "\n",
    "ax = p.plot(kind = 'barh', legend = False, figsize = (15,10))\n",
    "plt.title('Total pool: {:,} Movies, {:,} customers, {:,} ratings given'.format(movie_count, cust_count, rating_count), fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(1,6):\n",
    "    ax.text(p.iloc[i-1][0]/4, i-1, 'Rating {}: {:.0f}%'.format(i, p.iloc[i-1][0]*100 / p.sum()[0]), color = 'white', weight = 'bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "\n",
    "with open(f\"{dataset_path}/{movie_titles}\", encoding=\"ISO-8859-1\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        movie_id = int(row[0])\n",
    "        # Need to handle a few cases where the year is missing. \n",
    "        if row[1] == 'NULL':\n",
    "            year = -1\n",
    "        else:\n",
    "            year = int(row[1])\n",
    "        # Need to handle the case where a movie title has a comman in the name\n",
    "        name = ','.join(row[2:]) \n",
    "        titles.append([movie_id, year, name])\n",
    "\n",
    "df_titles = pd.DataFrame(titles, columns=['Movie_Id', 'Movie_Year', 'Name'])\n",
    "df_titles.set_index('Movie_Id', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ratings.join(df_titles, on='Movie_Id', how='inner')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No missing values\n",
    "na_check = df.isna().sum()\n",
    "print(na_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Enrich data with average rating and review count for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_ratings = df.groupby('Movie_Id')['Rating'].mean().reset_index()\n",
    "average_ratings.columns = ['Movie_Id', 'Average_Rating']\n",
    "\n",
    "review_counts = df.groupby('Movie_Id')['Rating'].count().reset_index()\n",
    "review_counts.columns = ['Movie_Id', 'Review_Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(average_ratings, on='Movie_Id', how='inner')\n",
    "df = df.merge(review_counts, on='Movie_Id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find set of N movies where the customers have rate all N movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_TOP_N = 20\n",
    "top_movies = review_counts.sort_values(by='Review_Count', ascending=False)['Movie_Id']\n",
    "top_n_movies = top_movies.head(KEEP_TOP_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_n = df[df['Movie_Id'].isin(top_n_movies)]\n",
    "print(df_top_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = df_top_n.pivot_table(index='Cust_Id', columns='Movie_Id', values='Rating', aggfunc='count', fill_value=0)\n",
    "\n",
    "customers_all_n_movies = pivot_table[pivot_table.sum(axis=1) == KEEP_TOP_N].index\n",
    "\n",
    "df_final = df_top_n[df_top_n['Cust_Id'].isin(customers_all_n_movies)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of customers who reviewed all {KEEP_TOP_N} movies: {len(customers_all_n_movies)}\")\n",
    "print(df_titles.loc[top_n_movies])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final dataset for experiment\n",
    "df_final.to_csv(f\"{dataset_path}/df_top_20_movies_customers_reviewed_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
